{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIKKYxxEPp-g"
      },
      "source": [
        "# **COLLEGAMENTO AL DRIVE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcLaY4irGnxR",
        "outputId": "dea16f22-9c8c-4989-ff42-1aacc1fa4eaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "%reset -f\n",
        "# Collegamento al drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)                               # Indirizzo base del drive "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LIBRERIE**"
      ],
      "metadata": {
        "id": "3K6te5JXwmof"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Pc7M4DmZZKzj"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/Garbage_Detection/GARBAGE_DETECTION')\n",
        "\n",
        "import my_stretch as st                               # Importa la libreria proprietaria my_stretch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdS7nX-SHXdR",
        "outputId": "2b2f97b7-d1fb-40e0-ae1f-e3bf57bcf0ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reset: invalid option -- 'f'\n",
            "Usage: tset [options] [terminal]\n",
            "\n",
            "Options:\n",
            "  -c          set control characters\n",
            "  -e ch       erase character\n",
            "  -I          no initialization strings\n",
            "  -i ch       interrupt character\n",
            "  -k ch       kill character\n",
            "  -m mapping  map identifier to type\n",
            "  -Q          do not output control key settings\n",
            "  -q          display term only, do no changes\n",
            "  -r          display term on stderr\n",
            "  -s          output TERM set command\n",
            "  -V          print curses-version\n",
            "  -w          set window-size\n",
            "\n",
            "If neither -c/-w are given, both are assumed.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/qubvel/segmentation_models\n",
            "  Cloning https://github.com/qubvel/segmentation_models to /tmp/pip-req-build-np2g8ij_\n",
            "  Running command git clone -q https://github.com/qubvel/segmentation_models /tmp/pip-req-build-np2g8ij_\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from segmentation-models==1.0.1) (1.0.8)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models==1.0.1) (1.0.0)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models==1.0.1) (1.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models==1.0.1) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2021.11.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!reset -f\n",
        "import numpy as np                                    # Importa Numpy\n",
        "import matplotlib.pyplot as plt                       # Importa il modulo  pyplot di MatPlotLib\n",
        "import skimage.io as io                               # Importa il modulo Input/ouput di SK-Image\n",
        "from tensorflow import keras                          # Importa il modulo Keras di TensorFlow\n",
        "import cv2                                            # Importa cv2\n",
        "import os                                             # Importa os                             \n",
        "import fnmatch                                        # Importa fnmatch\n",
        "import skimage.io as io                               # Importa il modulo Input/ouput di SK-Image\n",
        "from skimage.transform import resize                  # Importa il modulo resize da SK-Image\n",
        "from os import listdir                                # Importa il modulo listdir da OS\n",
        "\n",
        "from functools import lru_cache                       # Importa il modulo lru_cache da functools\n",
        "from matplotlib.collections import PatchCollection    # Importa PatchCollection dal modulo collections di MatPlotLib\n",
        "\n",
        "from PIL import Image                                 # Importa il modulo Image da PIL\n",
        "\n",
        "!pip install git+https://github.com/qubvel/segmentation_models\n",
        "os.environ['SM_FRAMEWORK'] = 'tf.keras'\n",
        "import segmentation_models as sm                      # Importa Segmentation Models usando il framework Keras\n",
        "from segmentation_models.metrics import iou_score     # Importa iou_score dal modulo Metrics di Segmentation Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PATH**"
      ],
      "metadata": {
        "id": "HtHz19PSwc3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/Garbage_Detection'                    # Path del progetto\n",
        "weight_path = '/content/drive/MyDrive/Garbage_Detection/pesi_ST/27.h5'    # Path dei pesi\n",
        "phone_path = data_path + '/Phone_Data'                                                # Path delle immagini da cellulare"
      ],
      "metadata": {
        "id": "4yLe0hp_vWZS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xqt3Q16O_1T"
      },
      "source": [
        "# **ISTANZIAMENTO RETE PER IL TRAINING E COMPILE E CARICAMENTO PESI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FzLsRCRDHo54"
      },
      "outputs": [],
      "source": [
        "# ISTANZIAMENTO RETE\n",
        "BACKBONE = 'resnet34'                                     # Rete Neurale di Encoding per la rete Unet\n",
        "model = sm.Unet(BACKBONE,                                 # Modello utilizzato come estrattore di feature di basso livello per costruire il modello di segmentazione\n",
        "                input_shape=(None, None, 3),              # Modello in grado di lavorare su qualsiasi dimensione\n",
        "                classes=1,                                 \n",
        "                activation='sigmoid',                     # L’output è in [0, 1] il che assicura un training più stabile durante la segmentazione con maschere\n",
        "                weights=None, \n",
        "                encoder_weights='imagenet',               # Pre-formazione su ImageNet\n",
        "                encoder_freeze=True,                      # Tutti i livelli dell'encoder sono settati come non addestrabili\n",
        "                encoder_features='default', \n",
        "                decoder_block_type='upsampling', \n",
        "                decoder_filters=(256, 128, 64, 32, 16), \n",
        "                decoder_use_batchnorm=True) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definizione die parametri per il training\n",
        "model.compile(loss = keras.losses.binary_crossentropy,                          # Loss-Function: Binary Cross-Entropy  dato che assume valori in [0;1]\n",
        "              optimizer = keras.optimizers.SGD(learning_rate=0.06),             # Algoritmo di ottimizzazione: Stochastic Gradient Descent (SGD), lr: 0.06\n",
        "              metrics = [iou_score, ])                                          # Misura di performance: Intersaction over Union, non influenzato dall'area da segmentare"
      ],
      "metadata": {
        "id": "2gVl0QmRvJIH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(weight_path)                                                 # Caricamento pesi"
      ],
      "metadata": {
        "id": "dT0zQptRvPeN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaYDky7VkSsy"
      },
      "source": [
        "# **DEFINIZIONE FUNZIONE DI STRETCH**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kzhXLU43pWGk"
      },
      "outputs": [],
      "source": [
        "@lru_cache(maxsize=None)          # Dimensione della cache (default:128, con None non diamo un limite ma consumiamo molte risorse --> Colab)\n",
        "def phone_stretch(batch_path, dimension):\n",
        "  ''' \n",
        "    Prende un'immagine alla volta dal dataset di test per cellulari, la stretcha a dimensione quadrata e la carica in un ndarray e lo memorizza in un  .npy (utilizza lru_cache)\n",
        "    ----------\n",
        "    PARAMETRI:\n",
        "      batch_path: indirizzo dei batch del dataset\n",
        "          string\n",
        "      dimension: dimensione dell'immagine quadrata in uscita\n",
        "          int\n",
        "\n",
        "    ----------\n",
        "    RETURN:\n",
        "      numpy.ndarray\n",
        "          4D-array (number_img x dimension x dimension X channel)\n",
        "  ''' \n",
        "  list_img_stretched = list()                                                   # Crea una lista vuota per le immagini stretchate\n",
        "\n",
        "  #filtro per soli jpg\n",
        "  print('Ci sono ' + str(len( fnmatch.filter(os.listdir(batch_path), '*.jpg' ) ))  + ' immagini da cellulare \\n')\n",
        "\n",
        "  # listdir: restituisce un elenco contenente i nomi delle voci nella directory data dal path\n",
        "  for fname in sorted( fnmatch.filter(os.listdir(batch_path), '*.jpg' ) ):                               \n",
        "\n",
        "    img = np.float32(io.imread(batch_path + '/' + fname))/255                   # Legge e normalizza le immagini \n",
        "\n",
        "    img_stretched = resize(img, (dimension, dimension), order=0)                # Stretcha le immagini in formato 512x512 con interpolazione Nearest-Neighbour\n",
        "    img_stretchedbn = np.expand_dims(img_stretched, axis=-1)                    # Aggiunge la quarta dimensione\n",
        "    \n",
        "    list_img_stretched.append(img_stretchedbn)                                  # Aggiunge un elemento alla fine dell'elenco\n",
        "\n",
        "\n",
        "  npa_stretched = np.array(list_img_stretched)                                  # Crea un array di tutte le immagini stretchate\n",
        "  \n",
        "  phone_img = np.resize( npa_stretched, (len(npa_stretched), 480, 480, 3)) \n",
        "  st.array_on_file(phone_path + '/phone.npy', phone_img)\n",
        "\n",
        "\n",
        "  return phone_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUbV_yVwI4eh"
      },
      "source": [
        "# **DEFINIZIONE DI FUNZIONE PER PREDIZIONE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1xZDpzD2B2FB"
      },
      "outputs": [],
      "source": [
        "@lru_cache(maxsize=None)\n",
        "def phone_predict(ID, phone_path):\n",
        "    ''' \n",
        "      Stampa l'immagine predetta con accanto l'originale e la segmentata\n",
        "      ----------\n",
        "      PARAMETRI:\n",
        "        ID: id dell'immagine scelta [1, len]\n",
        "          int\n",
        "        phone_path: stringa del path per le foto da cellulare\n",
        "          string\n",
        "      ----------\n",
        "    ''' \n",
        "\n",
        "    phone_img = st.array_from_file(phone_path + '/phone.npy')\n",
        "\n",
        "    # Prende singola immagine di TEST\n",
        "    img = phone_img[ID, :] \n",
        "\n",
        "\n",
        "    # PREDIZIONE SU SINGOLA IMMAGINE DI TEST\n",
        "    img_sing = np.expand_dims(img, axis=0)\n",
        "    pred = model.predict(img_sing) \n",
        "\n",
        "\n",
        "    # Preparazione al plot della predetta:\n",
        "    pred_img = pred[0,:] \n",
        "    pred_img = np.resize(pred, (480,480))\n",
        "\n",
        "    # PLOT\n",
        "    plt.figure(figsize=(18,6))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.title('ORIGINALE N°%d'%ID)\n",
        "    plt.imshow(img)\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.title('PREDETTA N°%d'%ID)\n",
        "    plt.imshow(pred_img, clim=[0,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pw4ah9BTH6qz"
      },
      "outputs": [],
      "source": [
        "@lru_cache(maxsize=None)\n",
        "def predict_phone_batch(phone_path):\n",
        "    ''' \n",
        "      Stampa tutte le immagini predette con accanto l'originale dalla cartella del cellulare\n",
        "      ----------\n",
        "      PARAMETRI:\n",
        "        phone_path: stringa del path per le foto da cellulare\n",
        "          string\n",
        "      ----------\n",
        "    ''' \n",
        "\n",
        "    phone_img = st.array_from_file(phone_path + '/phone.npy')\n",
        "\n",
        "    for ID in range(1,len(phone_img)):\n",
        "\n",
        "      # Prende singola immagine di TEST\n",
        "      img = phone_img[ID, :] \n",
        "\n",
        "\n",
        "      # PREDIZIONE SU SINGOLA IMMAGINE DI TEST\n",
        "      img_sing = np.expand_dims(img, axis=0)\n",
        "      pred = model.predict(img_sing) \n",
        "\n",
        "\n",
        "      # Preparazione al plot della predetta:\n",
        "      pred_img = pred[0,:] \n",
        "      pred_img = np.resize(pred, (480,480))\n",
        "\n",
        "      # PLOT\n",
        "      plt.figure(figsize=(18,6))\n",
        "      plt.subplot(1,3,1)\n",
        "      plt.title('ORIGINALE N°%d'%ID)\n",
        "      plt.imshow(img)\n",
        "      plt.subplot(1,3,2)\n",
        "      plt.title('PREDETTA N°%d'%ID)\n",
        "      plt.imshow(pred_img, clim=[0,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLzsyUs7XWzo"
      },
      "source": [
        "# **PHONE INPUT TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcM_NhWzXazj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43f8d92-15ea-44f7-84b2-573ef8b5d09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ci sono 40 immagini da cellulare \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# CARICA LE IMG DEL CELLULARE STRETCHATE SU UN VETTORE NPY\n",
        "\n",
        "dimension= 480        # Dimensioni immagini quadrate stretchate\n",
        "\n",
        "phone_img = phone_stretch(phone_path, dimension)\n",
        "print(phone_img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63k8Glts6tna"
      },
      "outputs": [],
      "source": [
        "# PREDIZIONE IMMAGINI DA CELLULARE\n",
        "predict_phone_batch(phone_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZqeeRT86u3i"
      },
      "outputs": [],
      "source": [
        "# PREDIZIONE SINGOLA IMMAGINE DA CELLULARE\n",
        "phone_predict(0, phone_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "EIKKYxxEPp-g",
        "3K6te5JXwmof",
        "HtHz19PSwc3U",
        "3xqt3Q16O_1T",
        "yaYDky7VkSsy",
        "VUbV_yVwI4eh"
      ],
      "name": "PHONE_IMG_DETECTOR.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}